{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Объявляем системные переменные","metadata":{}},{"cell_type":"code","source":"path_to_models = '/kaggle/input/gpt2got_v2'\npath_to_books = '/kaggle/input/game-of-thrones-book-files'\noutput_prefix = 'got'","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:14.617556Z","iopub.execute_input":"2022-02-07T15:25:14.61797Z","iopub.status.idle":"2022-02-07T15:25:14.64671Z","shell.execute_reply.started":"2022-02-07T15:25:14.617842Z","shell.execute_reply":"2022-02-07T15:25:14.646076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"препроцессинг текстов и функция, которая возвращает последний снепшот модели из папки снепшотов","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport re\n\ndef preprocessing(path_to_data):\n    list_of_true_names = ['got5.txt', 'got1.txt', 'got2.txt', 'got4.txt', 'got3.txt']\n    list_of_files = [os.path.join(path_to_data, i) for i in list_of_true_names]\n    print(list_of_files)\n    text = None\n    for file in list_of_files:\n        with open(file, 'r') as f:\n            if text is None:\n                text = f.read()\n            else:\n                text += f.read()\n    text = text.replace('“', '')\n    text = text.replace('”', '')\n    text = text.split('\\n')\n    text = [sentence.split('. ') for sentence in text]\n    text = sum(text, [])\n    text = [word for word in text if word != '' and word != '.']\n#     return text\n\n    new_list = []\n    for i in range(0, (len(text) // 10) * 10, 10):\n        new_list.append(text[i] + ' ' + \n                        text[i+1] + ' ' + \n                        text[i+2] + ' ' + \n                        text[i+3] + ' ' + \n                        text[i+4] + ' ' +\n                        text[i+5] + ' ' + \n                        text[i+6] + ' ' + \n                        text[i+7] + ' ' + \n                        text[i+8] + ' ' + \n                        text[i+9])\n    return new_list\n\ndef get_last_state_dict(path_to_data):\n    list_of_files = glob.glob(f\"{path_to_data}/*\")\n    array = []\n    for file in list_of_files:\n        array.append((file, int(re.findall('\\d+', file.split('/')[-1])[0])))\n    array.sort(key= lambda x: x[1], reverse=True)\n    path, epoch = array[0]\n    print(f'last state dict in {path}. epoch {epoch}')\n    return path, epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:14.64813Z","iopub.execute_input":"2022-02-07T15:25:14.648451Z","iopub.status.idle":"2022-02-07T15:25:14.661203Z","shell.execute_reply.started":"2022-02-07T15:25:14.648415Z","shell.execute_reply":"2022-02-07T15:25:14.660538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = preprocessing(path_to_books)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:25:14.662347Z","iopub.execute_input":"2022-02-07T15:25:14.663165Z","iopub.status.idle":"2022-02-07T15:26:13.0662Z","shell.execute_reply.started":"2022-02-07T15:25:14.663132Z","shell.execute_reply":"2022-02-07T15:26:13.065459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://githubhelp.com/EmilyNLP/Fine-Tune-GPT2-to-Generate-Stories\n\n# http://education.abcom.com/using-gpt-2-to-write-like-shakespeare/","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:13.068281Z","iopub.execute_input":"2022-02-07T15:26:13.068539Z","iopub.status.idle":"2022-02-07T15:26:13.072794Z","shell.execute_reply.started":"2022-02-07T15:26:13.068504Z","shell.execute_reply":"2022-02-07T15:26:13.072027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Датасеты и даталоадеры","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer, PreTrainedTokenizer\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nclass GameOfThronesDataset2(Dataset):\n    def __init__(self, list_of_sentences):\n        self.labels=[]\n        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        self.data = self.tokenizer(list_of_sentences, padding=True, return_attention_mask=True)\n        \n        labels=[]\n        for ids, attention_mask in zip(self.data['input_ids'],self.data['attention_mask']):\n            label=ids.copy()\n            real_len=sum(attention_mask)\n            padding_len=len(attention_mask)-sum(attention_mask)\n            label[:]=label[:real_len]+[-100]*padding_len\n            labels.append(label)\n            \n        self.data['labels']=labels\n        \n    def __len__(self):\n        return len(self.data['input_ids'])\n\n    def __getitem__(self, index):\n\n        return [torch.tensor(self.data['input_ids'][index], dtype=torch.long),\n                torch.tensor(self.data['attention_mask'][index], dtype=torch.long),\n                torch.tensor(self.data['labels'][index], dtype=torch.long)]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:13.074603Z","iopub.execute_input":"2022-02-07T15:26:13.074846Z","iopub.status.idle":"2022-02-07T15:26:19.702906Z","shell.execute_reply.started":"2022-02-07T15:26:13.074813Z","shell.execute_reply":"2022-02-07T15:26:19.702206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = text[:12000]\ntest = text[12000:]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:19.704522Z","iopub.execute_input":"2022-02-07T15:26:19.704805Z","iopub.status.idle":"2022-02-07T15:26:19.712129Z","shell.execute_reply.started":"2022-02-07T15:26:19.704767Z","shell.execute_reply":"2022-02-07T15:26:19.710935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = GameOfThronesDataset2(train)\ntest_dataset = GameOfThronesDataset2(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:19.715696Z","iopub.execute_input":"2022-02-07T15:26:19.715997Z","iopub.status.idle":"2022-02-07T15:26:47.641833Z","shell.execute_reply.started":"2022-02-07T15:26:19.715962Z","shell.execute_reply":"2022-02-07T15:26:47.641077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, RandomSampler\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8)\ntest_dataloader = DataLoader(test_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:47.643032Z","iopub.execute_input":"2022-02-07T15:26:47.6433Z","iopub.status.idle":"2022-02-07T15:26:47.648808Z","shell.execute_reply.started":"2022-02-07T15:26:47.643265Z","shell.execute_reply":"2022-02-07T15:26:47.647983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"инициализация","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\nfrom transformers import AdamW\nimport numpy as np\n# import gc\nfrom transformers.optimization import get_linear_schedule_with_warmup\n\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\nnum_train_epochs = 10\ntraining_steps_per_epoch=len(train_dataloader)\ntotal_num_training_steps = int(training_steps_per_epoch * num_train_epochs)\nweight_decay = 0\nlearning_rate = 5e-5\nadam_epsilon = 1e-8\nwarmup = 0.1\nwarmup_steps = int(total_num_training_steps * warmup)\n\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": weight_decay,\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\noptimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_num_training_steps\n)\n\n# gc.collect()\n# torch.cuda.empty_cache()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:56:29.002511Z","iopub.execute_input":"2022-02-11T16:56:29.003296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path, epoch = get_last_state_dict(path_to_models)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:27:10.165964Z","iopub.execute_input":"2022-02-07T15:27:10.16621Z","iopub.status.idle":"2022-02-07T15:27:10.171603Z","shell.execute_reply.started":"2022-02-07T15:27:10.166174Z","shell.execute_reply":"2022-02-07T15:27:10.17072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load(path))\n# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:27:10.172934Z","iopub.execute_input":"2022-02-07T15:27:10.17318Z","iopub.status.idle":"2022-02-07T15:27:10.185028Z","shell.execute_reply.started":"2022-02-07T15:27:10.173145Z","shell.execute_reply":"2022-02-07T15:27:10.184401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучение","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train2(traindataloader, testdataloader, model, optimizer, scheduler, device, epochs, output_dir, output_prefix, save_model_on_epoch, validate_every):\n    \n    losses_train_overall = []\n    losses_test_overall = []\n    \n    for i in range(epochs):\n        \n        print(f\"Training epoch {i}\")\n        model.train()\n        train_loss = []\n        test_loss = []\n        model.zero_grad() ###\n        optimizer.zero_grad()\n        for batch in tqdm(traindataloader, desc=\"train\"):\n            inputs, attention, labels = batch\n            inputs = inputs.to(device)\n#             inputs = inputs.squeeze(1).to(device)\n            attention = attention.to(device)\n            labels = labels.to(device)\n\n            outputs = model(input_ids=inputs, attention_mask=attention, labels=labels)\n            loss = outputs[0]\n\n            batch_loss = loss.cpu().item()\n            train_loss.append(batch_loss)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            model.zero_grad() ###\n            optimizer.zero_grad()\n            del loss\n            \n        train_loss_mean = np.mean(train_loss)\n        print(f'train loss = {train_loss_mean}')\n        print()\n\n        if (i % validate_every == 0):\n            \n            model.eval()\n            optimizer.zero_grad()\n            model.zero_grad()\n            \n            with torch.no_grad():\n                               \n                for batch in tqdm(testdataloader, desc=\"eval\"):\n                    inputs, attention, labels = batch\n                    inputs = inputs.to(device)\n#                     inputs = inputs.squeeze(1).to(device)\n                    attention = attention.to(device)\n                    labels = labels.to(device)\n                    \n                    outputs = model(input_ids=inputs, attention_mask=attention, labels=labels)\n                    loss = outputs[0]  \n                    \n                    batch_val_loss = loss.cpu().item()\n                    test_loss.append(batch_val_loss)\n                    del loss\n                    \n                test_loss_mean = np.mean(test_loss)\n                print(f'validate loss = {test_loss_mean}')\n                print()\n\n        if save_model_on_epoch:\n            torch.save(model.state_dict(), os.path.join(output_dir, f\"{output_prefix}-{epochs}.pt\"))\n\n        losses_train_overall.append(train_loss_mean)\n        losses_test_overall.append(test_loss_mean)\n    return losses_train_overall, losses_test_overall\n\nlist_train_loss, list_test_loss =  train2(\n    train_dataloader, \n    test_dataloader, \n    model, \n    optimizer, \n    scheduler, \n    device, \n    epochs=num_train_epochs, \n    output_dir=\"/kaggle/working\", \n    output_prefix='got_v2', \n    save_model_on_epoch=True, \n    validate_every=1\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:27:10.19483Z","iopub.execute_input":"2022-02-07T15:27:10.195957Z","iopub.status.idle":"2022-02-07T18:09:04.907045Z","shell.execute_reply.started":"2022-02-07T15:27:10.195932Z","shell.execute_reply":"2022-02-07T18:09:04.906154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Кривые обучения","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef learning_curves(train, val, txt='loss'):\n    plt.figure(figsize=(8,6))\n    plt.plot(range(1, len(train)+1), train, label='train {}'.format(txt))\n    plt.plot(range(1, len(val)+1), val, label='validation {}'.format(txt))\n\n    plt.title('Training history', fontsize=14)\n    plt.ylabel('{}'.format(txt), fontsize=14)\n    plt.xlabel('Epoch', fontsize=14)\n    plt.legend(fontsize=14)\n    plt.tick_params(axis='both', which='major', labelsize=14)\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:09:04.911911Z","iopub.execute_input":"2022-02-07T18:09:04.914093Z","iopub.status.idle":"2022-02-07T18:09:04.924799Z","shell.execute_reply.started":"2022-02-07T18:09:04.914049Z","shell.execute_reply":"2022-02-07T18:09:04.924133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves(list_train_loss, list_test_loss)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:09:04.928625Z","iopub.execute_input":"2022-02-07T18:09:04.930482Z","iopub.status.idle":"2022-02-07T18:09:05.157688Z","shell.execute_reply.started":"2022-02-07T18:09:04.930447Z","shell.execute_reply":"2022-02-07T18:09:05.157089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import chain\nlearning_curves(list(a), list(b))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T20:55:58.586296Z","iopub.execute_input":"2022-02-07T20:55:58.586548Z","iopub.status.idle":"2022-02-07T20:55:58.7847Z","shell.execute_reply.started":"2022-02-07T20:55:58.586521Z","shell.execute_reply":"2022-02-07T20:55:58.784046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"INFERENCE","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\nimport torch\n\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nmodel.load_state_dict(torch.load('/kaggle/input/model-snapshot/got_v2-20.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:59:52.271132Z","iopub.execute_input":"2022-02-11T16:59:52.271428Z","iopub.status.idle":"2022-02-11T17:00:00.298943Z","shell.execute_reply.started":"2022-02-11T16:59:52.271397Z","shell.execute_reply":"2022-02-11T17:00:00.297987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install rpunct","metadata":{"execution":{"iopub.status.busy":"2022-02-11T17:19:44.073083Z","iopub.execute_input":"2022-02-11T17:19:44.073591Z","iopub.status.idle":"2022-02-11T17:21:44.799858Z","shell.execute_reply.started":"2022-02-11T17:19:44.073557Z","shell.execute_reply":"2022-02-11T17:21:44.798667Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Расставляем пунктуацию","metadata":{}},{"cell_type":"code","source":"from rpunct import RestorePuncts\n# The default language is 'english'\nrpunct = RestorePuncts()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T17:21:49.593327Z","iopub.execute_input":"2022-02-11T17:21:49.593650Z","iopub.status.idle":"2022-02-11T17:22:16.098557Z","shell.execute_reply.started":"2022-02-11T17:21:49.593606Z","shell.execute_reply":"2022-02-11T17:22:16.097465Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Генерируем текст","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\n\ndataset_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ndataset_tokenizer.pad_token = dataset_tokenizer.eos_token\n\n\ndef generate(text, size='small'):\n    \"\"\"\n    size = small, middle, big\n    \"\"\"\n    dict_of_size = {'small': 100, 'middle': 200, 'big': 300}\n    ids = dataset_tokenizer.encode(text, return_tensors='pt').to(device)\n    greedy_output = model.generate(ids, do_sample=True, max_length=dict_of_size[size], top_k=40, top_p=0.95, num_return_sequences=3)\n    result = rpunct.punctuate(dataset_tokenizer.decode(greedy_output[0], skip_special_tokens=False))\n    return result\n\ngenerate('katelyn', 'small')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T17:33:19.398411Z","iopub.execute_input":"2022-02-11T17:33:19.398792Z","iopub.status.idle":"2022-02-11T17:33:25.399858Z","shell.execute_reply.started":"2022-02-11T17:33:19.398739Z","shell.execute_reply":"2022-02-11T17:33:25.398865Z"},"trusted":true},"execution_count":17,"outputs":[]}]}