{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Объявляем системные переменные","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nimport seaborn as sns\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import GPT2Tokenizer\nimport os\nimport glob\nimport re\nimport numpy as np\nimport itertools\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom transformers import GPT2LMHeadModel\nfrom transformers import AdamW\nfrom transformers.optimization import get_linear_schedule_with_warmup\n\npath_to_models = '/kaggle/input/modelsnapshots'\n\n# path_to_witcher_1 = '/kaggle/input/witcher-book'\n# path_to_lotr_2 = '/kaggle/input/lord-of-the-ring'\n# path_to_got_3 = '/kaggle/input/game-of-thrones-book-files'\npath_to_all = '/kaggle/input/fantasy-books'\n\noutput_prefix = 'fantasy'","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:30:19.784235Z","iopub.execute_input":"2022-02-16T18:30:19.784596Z","iopub.status.idle":"2022-02-16T18:30:19.795593Z","shell.execute_reply.started":"2022-02-16T18:30:19.784557Z","shell.execute_reply":"2022-02-16T18:30:19.794596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"препроцессинг текстов и функция, которая возвращает последний снепшот модели из папки снепшотов","metadata":{}},{"cell_type":"code","source":"def prep(path_to_data, list_of_true_names, max_len_of_sent, max_len_of_paragraph):\n    list_of_files = [os.path.join(path_to_data, i) for i in list_of_true_names]\n#     print(list_of_files)\n    text = None\n    for file in list_of_files:\n        with open(file, 'r') as f:\n            if text is None:\n                text = f.read()\n            else:\n                text += f.read()\n    text = text.replace('\\n', ' ')\n    text = text.replace('***', '')\n    text = text.replace('“', \"'\")\n    text = text.replace('”', \"'\")\n    text = text.replace('’', \"'\")\n    text = text.replace('‘', \"'\")\n    text = sent_tokenize(text)\n    print(\"top 20 the longest sent: \" + str(sorted([len(sent.split()) for sent in text], reverse=True)[:20]))\n    print(f\"Deleteing sentences with more than {max_len_of_sent} words...\")\n    list_of_lens = [len(sent.split()) for sent in text if len(sent.split()) < max_len_of_sent]\n    text = [sent for sent in text if len(sent.split()) < max_len_of_sent]\n#     return text\n\n    print(f\"Perform paragraphs with less than {max_len_of_paragraph} words from sentences...\")\n    list_of_paragraph_lens = []\n    improved_text_array = []\n    i = 0\n    list_of_paragraph_lens.append([list_of_lens[0]])\n    improved_text_array.append(text[0])\n    for j in range(1, len(list_of_lens)-2):\n        if sum(list_of_paragraph_lens[i]) + list_of_lens[j] < max_len_of_paragraph:\n            list_of_paragraph_lens[i].append(list_of_lens[j])\n            improved_text_array[i] += ' ' + text[j]\n        else:\n            list_of_paragraph_lens.append([list_of_lens[j]])\n            improved_text_array.append(text[j])\n            i += 1\n    improved_text_array[i] += ' ' + text[-1]\n#     return improved_text_array\n          \n    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n    tokenizer.pad_token = tokenizer.eos_token\n    list_of_tokens = [len(tokenizer.encode(sent)) for sent in improved_text_array]\n    print(\"top 20 the longest tokens: \" + str(sorted(list_of_tokens, reverse=True)[:20]))\n    print(\"top 20 the smallest tokens: \" + str(sorted(list_of_tokens)[:20]))\n    sns.histplot(list_of_tokens)\n    return improved_text_array, list_of_tokens","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:44:55.129144Z","iopub.execute_input":"2022-02-16T11:44:55.129387Z","iopub.status.idle":"2022-02-16T11:44:55.144462Z","shell.execute_reply.started":"2022-02-16T11:44:55.129356Z","shell.execute_reply":"2022-02-16T11:44:55.14373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"witcher_order = [\n        'Andrzej_Sapkowski_-_The_Last_Wish.txt',\n        '5_Sword_of_Destiny_The_Witcher_5_by_Andrzej_Sapkowski.txt',\n        '2_Blood_of_Elves_The_Witcher_Book_2_by_Sapkowski_Andrzej.txt',\n        '3_The_Time_of_Contempt_The_Witcher_Book_3_by_Sapkowski_Andrzej.txt',\n        '4_Baptism_of_Fire_The_Witcher_4_by_Andrzej_Sapkowski.txt',\n        '6_The_Tower_of_the_Swallow_The_Witcher_6_by_Andrzej_Sapkowski.txt',\n        'Andrzej_Sapkowski_-_The_Lady_of_the_Lake.txt',\n        'Andrzej_Sapkowski_-_Season_of_Storms.txt'\n]\n\ngot_order = ['got5.txt', 'got1.txt', 'got2.txt', 'got4.txt', 'got3.txt']\n\nlotr_order = [\n        'dzhon_ronald_ruel_tolkin-the_hobbit.txt',\n        'dzhon_ronald_ruel_tolkin-the_lord_of_the_rings.txt'\n]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:44:55.145884Z","iopub.execute_input":"2022-02-16T11:44:55.146332Z","iopub.status.idle":"2022-02-16T11:44:55.154406Z","shell.execute_reply.started":"2022-02-16T11:44:55.146294Z","shell.execute_reply":"2022-02-16T11:44:55.153625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_got, list_of_tokens_got = prep(path_to_all, got_order, max_len_of_sent=200, max_len_of_paragraph=500)\n# print(len(text_got))\n# text_got[np.argmin(np.array(list_of_tokens_got))], text_got[np.argmax(np.array(list_of_tokens_got))]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:22:19.240439Z","iopub.execute_input":"2022-02-16T11:22:19.24164Z","iopub.status.idle":"2022-02-16T11:22:19.246464Z","shell.execute_reply.started":"2022-02-16T11:22:19.241587Z","shell.execute_reply":"2022-02-16T11:22:19.245223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_witcher, list_of_tokens_witcher = prep(path_to_all, witcher_order, max_len_of_sent=200, max_len_of_paragraph=500)\n# print(len(text_witcher))\n# text_witcher[np.argmin(np.array(list_of_tokens_witcher))], text_witcher[np.argmax(np.array(list_of_tokens_witcher))]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:24:13.438894Z","iopub.execute_input":"2022-02-16T11:24:13.439187Z","iopub.status.idle":"2022-02-16T11:24:13.443862Z","shell.execute_reply.started":"2022-02-16T11:24:13.439157Z","shell.execute_reply":"2022-02-16T11:24:13.442457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text_lotr, list_of_tokens_lotr = prep(path_to_all, lotr_order, max_len_of_sent=200, max_len_of_paragraph=500)\n# print(len(text_lotr))\n# text_lotr[np.argmin(np.array(list_of_tokens_lotr))], text_lotr[np.argmax(np.array(list_of_tokens_lotr))]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:25:48.876851Z","iopub.execute_input":"2022-02-16T11:25:48.877816Z","iopub.status.idle":"2022-02-16T11:25:48.88259Z","shell.execute_reply.started":"2022-02-16T11:25:48.877763Z","shell.execute_reply":"2022-02-16T11:25:48.881648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_all, list_of_tokens_all = prep(\n    path_to_all,\n    itertools.chain(witcher_order, lotr_order, got_order),\n    max_len_of_sent=200,\n    max_len_of_paragraph=161\n)\nprint(len(text_all))\ntext_all[np.argmin(np.array(list_of_tokens_all))], text_all[np.argmax(np.array(list_of_tokens_all))]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:44:55.157531Z","iopub.execute_input":"2022-02-16T11:44:55.158549Z","iopub.status.idle":"2022-02-16T11:45:46.915091Z","shell.execute_reply.started":"2022-02-16T11:44:55.158498Z","shell.execute_reply":"2022-02-16T11:45:46.914412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_last_state_dict(path_to_data):\n    list_of_files = glob.glob(f\"{path_to_data}/*\")\n    array = []\n    for file in list_of_files:\n        array.append((file, int(re.findall('\\d+', file.split('/')[-1])[0])))\n    array.sort(key= lambda x: x[1], reverse=True)\n    path, epoch = array[0]\n    print(f'last state dict in {path}. epoch {epoch}')\n    return path, epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:31:36.793536Z","iopub.execute_input":"2022-02-16T18:31:36.794248Z","iopub.status.idle":"2022-02-16T18:31:36.800092Z","shell.execute_reply.started":"2022-02-16T18:31:36.794209Z","shell.execute_reply":"2022-02-16T18:31:36.799005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://githubhelp.com/EmilyNLP/Fine-Tune-GPT2-to-Generate-Stories\n\n# http://education.abcom.com/using-gpt-2-to-write-like-shakespeare/","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:13.068281Z","iopub.execute_input":"2022-02-07T15:26:13.068539Z","iopub.status.idle":"2022-02-07T15:26:13.072794Z","shell.execute_reply.started":"2022-02-07T15:26:13.068504Z","shell.execute_reply":"2022-02-07T15:26:13.072027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Датасеты и даталоадеры","metadata":{}},{"cell_type":"code","source":"class GameOfThronesDataset(Dataset):\n    def __init__(self, list_of_sentences):\n        self.labels=[]\n        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        self.data = self.tokenizer(list_of_sentences, padding=True, return_attention_mask=True)\n        \n        labels=[]\n        for ids, attention_mask in zip(self.data['input_ids'], self.data['attention_mask']):\n            label=ids.copy()\n            real_len=sum(attention_mask)\n            padding_len=len(attention_mask)-sum(attention_mask)\n            label[:]=label[:real_len]+[-100]*padding_len\n            labels.append(label)\n            \n        self.data['labels']=labels\n        \n        print('length of sent: ', len(self.data['input_ids'][0]))\n        print('length of data: ', len(self.data['input_ids']))\n        \n    def __len__(self):\n        return len(self.data['input_ids'])\n\n    def __getitem__(self, index):\n\n        return [torch.tensor(self.data['input_ids'][index], dtype=torch.long),\n                torch.tensor(self.data['attention_mask'][index], dtype=torch.long),\n                torch.tensor(self.data['labels'][index], dtype=torch.long)]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:45:46.916387Z","iopub.execute_input":"2022-02-16T11:45:46.916881Z","iopub.status.idle":"2022-02-16T11:45:46.927177Z","shell.execute_reply.started":"2022-02-16T11:45:46.916842Z","shell.execute_reply":"2022-02-16T11:45:46.926462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_dataset = GameOfThronesDataset(text_all)\nDataloader = DataLoader(text_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:45:46.928498Z","iopub.execute_input":"2022-02-16T11:45:46.929088Z","iopub.status.idle":"2022-02-16T11:46:24.450933Z","shell.execute_reply.started":"2022-02-16T11:45:46.929009Z","shell.execute_reply":"2022-02-16T11:46:24.449954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = text[:12000]\n# test = text[12000:]\n# train_dataset = GameOfThronesDataset2(train)\n# test_dataset = GameOfThronesDataset2(test)\n# train_dataloader = DataLoader(train_dataset, batch_size=8)\n# test_dataloader = DataLoader(test_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:26:19.715696Z","iopub.execute_input":"2022-02-07T15:26:19.715997Z","iopub.status.idle":"2022-02-07T15:26:47.641833Z","shell.execute_reply.started":"2022-02-07T15:26:19.715962Z","shell.execute_reply":"2022-02-07T15:26:47.641077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"инициализация","metadata":{}},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('gpt2')\n\nnum_train_epochs = 10\ntraining_steps_per_epoch=len(Dataloader)\ntotal_num_training_steps = int(training_steps_per_epoch * num_train_epochs)\nweight_decay = 0\nlearning_rate = 5e-5\nadam_epsilon = 1e-8\nwarmup = 0.1\nwarmup_steps = int(total_num_training_steps * warmup)\n\nno_decay = [\"bias\", \"LayerNorm.weight\"]\noptimizer_grouped_parameters = [\n    {\n        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n        \"weight_decay\": weight_decay,\n    },\n    {\n        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n        \"weight_decay\": 0.0,\n    },\n]\noptimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_num_training_steps\n)\n\n# gc.collect()\n# torch.cuda.empty_cache()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T11:46:24.453132Z","iopub.execute_input":"2022-02-16T11:46:24.453387Z","iopub.status.idle":"2022-02-16T11:46:46.253224Z","shell.execute_reply.started":"2022-02-16T11:46:24.453352Z","shell.execute_reply":"2022-02-16T11:46:46.252376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path, epoch = get_last_state_dict(path_to_models)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:27:10.165964Z","iopub.execute_input":"2022-02-07T15:27:10.16621Z","iopub.status.idle":"2022-02-07T15:27:10.171603Z","shell.execute_reply.started":"2022-02-07T15:27:10.166174Z","shell.execute_reply":"2022-02-07T15:27:10.17072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load(path))\n# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T15:27:10.172934Z","iopub.execute_input":"2022-02-07T15:27:10.17318Z","iopub.status.idle":"2022-02-07T15:27:10.185028Z","shell.execute_reply.started":"2022-02-07T15:27:10.173145Z","shell.execute_reply":"2022-02-07T15:27:10.184401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучение","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(traindataloader, model, optimizer, scheduler, device, epochs, output_dir, output_prefix, save_model_on_epoch, validate_every, testdataloader=None):\n    \n    losses_train_overall = []\n    losses_test_overall = []\n    \n    for i in range(epochs):\n        \n        print(f\"Training epoch {i}\")\n        model.train()\n        train_loss = []\n        test_loss = []\n        model.zero_grad() ###\n        optimizer.zero_grad()\n        for batch in tqdm(traindataloader, desc=\"train\"):\n            inputs, attention, labels = batch\n            inputs = inputs.to(device)\n#             inputs = inputs.squeeze(1).to(device)\n            attention = attention.to(device)\n            labels = labels.to(device)\n\n            outputs = model(input_ids=inputs, attention_mask=attention, labels=labels)\n            loss = outputs[0]\n\n            batch_loss = loss.cpu().item()\n            train_loss.append(batch_loss)\n\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            model.zero_grad() ###\n            optimizer.zero_grad()\n            del loss\n            \n        train_loss_mean = np.mean(train_loss)\n        print(f'train loss = {train_loss_mean}')\n        print()\n\n#         if (i % validate_every == 0):\n            \n#             model.eval()\n#             optimizer.zero_grad()\n#             model.zero_grad()\n            \n#             with torch.no_grad():\n                               \n#                 for batch in tqdm(testdataloader, desc=\"eval\"):\n#                     inputs, attention, labels = batch\n#                     inputs = inputs.to(device)\n# #                     inputs = inputs.squeeze(1).to(device)\n#                     attention = attention.to(device)\n#                     labels = labels.to(device)\n                    \n#                     outputs = model(input_ids=inputs, attention_mask=attention, labels=labels)\n#                     loss = outputs[0]  \n                    \n#                     batch_val_loss = loss.cpu().item()\n#                     test_loss.append(batch_val_loss)\n#                     del loss\n                    \n#                 test_loss_mean = np.mean(test_loss)\n#                 print(f'validate loss = {test_loss_mean}')\n#                 print()\n\n        if save_model_on_epoch:\n            torch.save(model.state_dict(), os.path.join(output_dir, f\"{output_prefix}-{i}.pt\"))\n\n        losses_train_overall.append(train_loss_mean)\n#         losses_test_overall.append(test_loss_mean)\n    return losses_train_overall, losses_test_overall\n\nlist_train_loss2, list_test_loss2 =  train(\n    Dataloader, \n    model, \n    optimizer, \n    scheduler, \n    device, \n    epochs=num_train_epochs, \n    output_dir=\"/kaggle/working\", \n    output_prefix=output_prefix, \n    save_model_on_epoch=True, \n    validate_every=1,\n    testdataloader=None\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:17:00.018126Z","iopub.execute_input":"2022-02-16T15:17:00.018377Z","iopub.status.idle":"2022-02-16T18:23:52.513884Z","shell.execute_reply.started":"2022-02-16T15:17:00.018349Z","shell.execute_reply":"2022-02-16T18:23:52.513007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Кривые обучения","metadata":{}},{"cell_type":"code","source":"def learning_curves(train, val, txt='loss'):\n    plt.figure(figsize=(8,6))\n    plt.plot(range(1, len(train)+1), train, label='train {}'.format(txt))\n    plt.plot(range(1, len(val)+1), val, label='validation {}'.format(txt))\n\n    plt.title('Training history', fontsize=14)\n    plt.ylabel('{}'.format(txt), fontsize=14)\n    plt.xlabel('Epoch', fontsize=14)\n    plt.legend(fontsize=14)\n    plt.tick_params(axis='both', which='major', labelsize=14)\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:15:26.862014Z","iopub.execute_input":"2022-02-16T15:15:26.863126Z","iopub.status.idle":"2022-02-16T15:15:26.870708Z","shell.execute_reply.started":"2022-02-16T15:15:26.863084Z","shell.execute_reply":"2022-02-16T15:15:26.86976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_curves(list_train_loss2, list_test_loss2)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T18:24:39.30944Z","iopub.execute_input":"2022-02-16T18:24:39.309691Z","iopub.status.idle":"2022-02-16T18:24:39.513903Z","shell.execute_reply.started":"2022-02-16T18:24:39.309663Z","shell.execute_reply":"2022-02-16T18:24:39.513246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from itertools import chain\n# learning_curves(list(a), list(b))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T20:55:58.586296Z","iopub.execute_input":"2022-02-07T20:55:58.586548Z","iopub.status.idle":"2022-02-07T20:55:58.7847Z","shell.execute_reply.started":"2022-02-07T20:55:58.586521Z","shell.execute_reply":"2022-02-07T20:55:58.784046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"INFERENCE","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\nimport glob\nimport re\n\npath_to_models = '/kaggle/input/modelsnapshots'\n\n# path_to_all = '/kaggle/input/fantasy-books'\n# output_prefix = 'fantasy'","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:40:29.173119Z","iopub.execute_input":"2022-02-16T19:40:29.173748Z","iopub.status.idle":"2022-02-16T19:40:29.177438Z","shell.execute_reply.started":"2022-02-16T19:40:29.173714Z","shell.execute_reply":"2022-02-16T19:40:29.176753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_last_state_dict(path_to_data):\n    list_of_files = glob.glob(f\"{path_to_data}/*\")\n    array = []\n    for file in list_of_files:\n        array.append((file, int(re.findall('\\d+', file.split('/')[-1])[0])))\n    array.sort(key= lambda x: x[1], reverse=True)\n    path, epoch = array[0]\n    print(f'last state dict in {path}. epoch {epoch}')\n    return path, epoch","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:40:03.190505Z","iopub.execute_input":"2022-02-16T19:40:03.190987Z","iopub.status.idle":"2022-02-16T19:40:03.19682Z","shell.execute_reply.started":"2022-02-16T19:40:03.190952Z","shell.execute_reply":"2022-02-16T19:40:03.195806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path, epoch = get_last_state_dict(path_to_models)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:40:32.302715Z","iopub.execute_input":"2022-02-16T19:40:32.302995Z","iopub.status.idle":"2022-02-16T19:40:32.309321Z","shell.execute_reply.started":"2022-02-16T19:40:32.302965Z","shell.execute_reply":"2022-02-16T19:40:32.308603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('gpt2')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nmodel.load_state_dict(torch.load(path))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:40:34.800293Z","iopub.execute_input":"2022-02-16T19:40:34.801166Z","iopub.status.idle":"2022-02-16T19:41:06.133194Z","shell.execute_reply.started":"2022-02-16T19:40:34.801114Z","shell.execute_reply":"2022-02-16T19:41:06.132504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Генерируем текст","metadata":{}},{"cell_type":"code","source":"dataset_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ndataset_tokenizer.pad_token = dataset_tokenizer.eos_token\n\n\ndef generate(text, size='small'):\n    \"\"\"\n    size = small, middle, big\n    \"\"\"\n    dict_of_size = {'extrasmall':50, 'small': 100, 'middle': 150, 'big': 200}\n    ids = dataset_tokenizer.encode(text, return_tensors='pt').to(device)\n    greedy_output = model.generate(ids, do_sample=True, max_length=dict_of_size[size], top_k=40, top_p=0.95, num_return_sequences=3)\n    result = dataset_tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n    return result\n\ngenerate(dataset_tokenizer.bos_token, 'middle')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:43:36.738063Z","iopub.execute_input":"2022-02-16T19:43:36.738602Z","iopub.status.idle":"2022-02-16T19:43:43.094124Z","shell.execute_reply.started":"2022-02-16T19:43:36.738557Z","shell.execute_reply":"2022-02-16T19:43:43.093395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = generate(dataset_tokenizer.bos_token, 'extrasmall')\nfor _ in range(10):\n    predict += generate(predict[-1], 'extrasmall')\n    \npredict","metadata":{"execution":{"iopub.status.busy":"2022-02-16T19:43:45.709217Z","iopub.execute_input":"2022-02-16T19:43:45.709812Z","iopub.status.idle":"2022-02-16T19:43:53.615582Z","shell.execute_reply.started":"2022-02-16T19:43:45.709774Z","shell.execute_reply":"2022-02-16T19:43:53.614056Z"},"trusted":true},"execution_count":null,"outputs":[]}]}